{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HairSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHrFbCOl4ufN",
        "outputId": "3a7f5409-6417-4151-dab7-292844030052"
      },
      "source": [
        "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3\" -O dataset-large.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-22 16:06:45--  https://docs.google.com/uc?export=download&confirm=1ydf&id=1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.13.78, 2607:f8b0:4004:808::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.13.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e=download [following]\n",
            "--2021-01-22 16:06:45--  https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e=download\n",
            "Resolving doc-14-5g-docs.googleusercontent.com (doc-14-5g-docs.googleusercontent.com)... 172.217.13.65, 2607:f8b0:4004:808::2001\n",
            "Connecting to doc-14-5g-docs.googleusercontent.com (doc-14-5g-docs.googleusercontent.com)|172.217.13.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=lvqlthvart21s&continue=https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e%3Ddownload&hash=jip8uobfv21hn97cq427s9vuirtglo08 [following]\n",
            "--2021-01-22 16:06:45--  https://docs.google.com/nonceSigner?nonce=lvqlthvart21s&continue=https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e%3Ddownload&hash=jip8uobfv21hn97cq427s9vuirtglo08\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.13.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e=download&nonce=lvqlthvart21s&user=09881555074476116646Z&hash=u36dd2j26n44hpvslgmi1hnhdrbiui51 [following]\n",
            "--2021-01-22 16:06:45--  https://doc-14-5g-docs.googleusercontent.com/docs/securesc/q9kkr7t13qqib58jgp6rtnb2tfv4m6fc/7ssa0qf22k933mdfpqrl7rcaq3h9mt8c/1611331575000/04205927457588895310/09881555074476116646Z/1hGVJJ0MERaP1ouEc_vcfFg1nS9aHeYw3?e=download&nonce=lvqlthvart21s&user=09881555074476116646Z&hash=u36dd2j26n44hpvslgmi1hnhdrbiui51\n",
            "Connecting to doc-14-5g-docs.googleusercontent.com (doc-14-5g-docs.googleusercontent.com)|172.217.13.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘dataset-large.zip’\n",
            "\n",
            "dataset-large.zip       [             <=>    ]   2.23G  81.9MB/s               "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFDbD6r4z3h"
      },
      "source": [
        "! mkdir dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od0w6Ieh42A2"
      },
      "source": [
        "! unzip /content/dataset-large.zip -d /content/dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zQvAiXlAtY"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.metrics import Recall, Precision\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Input, BatchNormalization, Dropout\r\n",
        "from tensorflow.keras.layers import UpSampling2D, Concatenate, Dropout, Conv2DTranspose\r\n",
        "import json\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tqdm import tqdm\r\n",
        "from tensorflow.keras.utils import Sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsaSHLlybO9A"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GQy6mk3mEAF"
      },
      "source": [
        "class Unet:\r\n",
        "    def __init__(self, input_shape):\r\n",
        "        self.input_shape = input_shape\r\n",
        "        self.model = tf.keras.Sequential()\r\n",
        "        self.L = 0\r\n",
        "        self.inputs = None\r\n",
        "\r\n",
        "    def down_sampling_block(self, inputs, num_conv_block, num_filter, kernel_size, activation):\r\n",
        "        for i in range(num_conv_block):\r\n",
        "            if self.L == 0:\r\n",
        "                inputs = Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                activation=activation, padding='same')(self.inputs)\r\n",
        "            else:\r\n",
        "                inputs = Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                activation=activation, padding='same')(inputs)\r\n",
        "            self.L += 1\r\n",
        "        outputs = MaxPool2D(pool_size=(2, 2))(inputs)\r\n",
        "        self.L += 1\r\n",
        "        return outputs, inputs\r\n",
        "\r\n",
        "    def conv_block(self, inputs, num_conv_block, num_filter, kernel_size, activation):\r\n",
        "        for i in range(num_conv_block):\r\n",
        "            if self.L == 0:\r\n",
        "                inputs = Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                activation=activation, padding='same')(self.inputs)\r\n",
        "            else:\r\n",
        "                inputs = (Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                 activation=activation, padding='same'))(inputs)\r\n",
        "            self.L += 1\r\n",
        "        outputs = inputs\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def up_sampling_block(self, inputs, concat, num_conv_block, num_filter, kernel_size, activation):\r\n",
        "        for i in range(num_conv_block):\r\n",
        "            if self.L == 0:\r\n",
        "                inputs = Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                activation=activation, padding='same')(self.inputs)\r\n",
        "            else:\r\n",
        "                inputs = (Conv2D(filters=num_filter, kernel_size=kernel_size,\r\n",
        "                                 activation=activation, padding='same'))(inputs)\r\n",
        "            self.L += 1\r\n",
        "        #outputs = UpSampling2D((2, 2))(inputs)[..., num_filter//2:]\r\n",
        "        outputs = Conv2DTranspose(filters=num_filter//2, kernel_size=kernel_size,\r\n",
        "                                  strides=(2, 2), padding='same')(inputs)\r\n",
        "        shape_enc = concat.shape[1]\r\n",
        "        shape_dec = outputs.shape[1]\r\n",
        "        index = (shape_enc-shape_dec)//2\r\n",
        "        concat = concat[:, index:index+shape_dec, index:index+shape_dec, :]\r\n",
        "        outputs = Concatenate()([concat, outputs])\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def build(self):\r\n",
        "        self.inputs = Input(shape=self.input_shape)\r\n",
        "        down1, concat1 = self.down_sampling_block(inputs=None, num_conv_block=2, num_filter=32,\r\n",
        "                                                  kernel_size=(3, 3), activation='relu')\r\n",
        "        down2, concat2 = self.down_sampling_block(inputs=down1, num_conv_block=2, num_filter=64,\r\n",
        "                                                  kernel_size=(3, 3), activation='relu')\r\n",
        "        down3, concat3 = self.down_sampling_block(inputs=down2, num_conv_block=2, num_filter=128,\r\n",
        "                                                  kernel_size=(3, 3), activation='relu')\r\n",
        "        down4, concat4 = self.down_sampling_block(inputs=down3, num_conv_block=2, num_filter=256,\r\n",
        "                                                  kernel_size=(3, 3), activation='relu')\r\n",
        "        up1 = self.up_sampling_block(inputs=down4, concat=concat4, num_conv_block=2, num_filter=512,\r\n",
        "                                     kernel_size=(3, 3), activation='relu')\r\n",
        "        up2 = self.up_sampling_block(inputs=up1, concat=concat3, num_conv_block=2, num_filter=256,\r\n",
        "                                     kernel_size=(3, 3), activation='relu')\r\n",
        "        up3 = self.up_sampling_block(inputs=up2, concat=concat2, num_conv_block=2, num_filter=128,\r\n",
        "                                     kernel_size=(3, 3), activation='relu')\r\n",
        "        up4 = self.up_sampling_block(inputs=up3, concat=concat1, num_conv_block=2, num_filter=64,\r\n",
        "                                     kernel_size=(3, 3), activation='relu')\r\n",
        "        conv1 = self.conv_block(inputs=up4, num_conv_block=2, num_filter=32,\r\n",
        "                                kernel_size=(3, 3), activation='relu')\r\n",
        "        output = self.conv_block(inputs=conv1, num_conv_block=1, num_filter=1,\r\n",
        "                                 kernel_size=(1, 1), activation='sigmoid')\r\n",
        "        model = Model(self.inputs, output)\r\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZUSmEPDmHYg"
      },
      "source": [
        "class DataAugmentation:\r\n",
        "    def __init__(self, input_size, output_size):\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "\r\n",
        "    def resize_image(self, image, mask):\r\n",
        "        w = image.shape[1]\r\n",
        "        h = image.shape[0]\r\n",
        "        ratio = min(w, h)/max(w, h)\r\n",
        "        if w >= h:\r\n",
        "            new_w = self.input_size\r\n",
        "            new_h = round(self.input_size*ratio)\r\n",
        "        else:\r\n",
        "            new_h = self.input_size\r\n",
        "            new_w = round(self.input_size*ratio)\r\n",
        "        image_resized = cv2.resize(image, (new_w, new_h))\r\n",
        "        mask_resized = cv2.resize(mask, (new_w, new_h))\r\n",
        "        return image_resized, mask_resized\r\n",
        "\r\n",
        "    def padding_image(self, image, mask):\r\n",
        "        h = image.shape[0]\r\n",
        "        w = image.shape[1]\r\n",
        "        image_padded = cv2.copyMakeBorder(image,\r\n",
        "                                          top=(self.input_size - h) // 2,\r\n",
        "                                          bottom=self.input_size - (self.input_size - h) // 2 - h,\r\n",
        "                                          left=(self.input_size - w) // 2,\r\n",
        "                                          right=self.input_size - (self.input_size - w) // 2 - w,\r\n",
        "                                          borderType=cv2.BORDER_CONSTANT)\r\n",
        "        mask_padded = cv2.copyMakeBorder(mask,\r\n",
        "                                         top=(self.input_size - h) // 2,\r\n",
        "                                         bottom=self.input_size - (self.input_size - h) // 2 - h,\r\n",
        "                                         left=(self.input_size - w) // 2,\r\n",
        "                                         right=self.input_size - (self.input_size - w) // 2 - w,\r\n",
        "                                         borderType=cv2.BORDER_CONSTANT)\r\n",
        "        return image_padded, mask_padded\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def random_rotation(image, mask):\r\n",
        "        degree = np.random.uniform(0, 360)\r\n",
        "        h = image.shape[0]\r\n",
        "        w = image.shape[1]\r\n",
        "        rot_map = cv2.getRotationMatrix2D((w//2, h//2), degree, scale=1)\r\n",
        "        image_rotated = cv2.warpAffine(image, rot_map, (w, h))\r\n",
        "        mask_rotated = cv2.warpAffine(mask, rot_map, (w, h))\r\n",
        "        return image_rotated, mask_rotated\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def random_flip(image, mask):\r\n",
        "        if np.random.choice([0, 1]):\r\n",
        "            flip_code = np.random.choice([-1, 0, 1])\r\n",
        "            image_flipped = cv2.flip(image, flipCode=flip_code)\r\n",
        "            mask_flipped = cv2.flip(mask, flipCode=flip_code)\r\n",
        "            return image_flipped, mask_flipped\r\n",
        "        return image, mask\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def random_blur(image, mask):\r\n",
        "        if np.random.choice([0, 1]):\r\n",
        "            radius = np.random.choice([1, 3, 5])\r\n",
        "            image_blur = cv2.GaussianBlur(image, ksize=(radius, radius), sigmaX=1)\r\n",
        "            mask_blur = cv2.GaussianBlur(mask, ksize=(radius, radius), sigmaX=1)\r\n",
        "            return image_blur, mask_blur\r\n",
        "        return image, mask\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def random_add_brightness(image):\r\n",
        "        value = np.random.randint(0, 50)\r\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
        "        h, s, v = cv2.split(hsv)\r\n",
        "        lim = 255 - value\r\n",
        "        v[v > lim] = 255\r\n",
        "        v[v <= lim] += value\r\n",
        "\r\n",
        "        image_brightness = cv2.merge((h, s, v))\r\n",
        "        image_brightness = cv2.cvtColor(image_brightness, cv2.COLOR_HSV2BGR)\r\n",
        "        return image_brightness\r\n",
        "\r\n",
        "    def data_process(self, image, mask):\r\n",
        "        image_processed, mask_processed = self.resize_image(image, mask)\r\n",
        "        image_processed, mask_processed = self.padding_image(image_processed, mask_processed)\r\n",
        "        image_processed, mask_processed = self.random_rotation(image_processed, mask_processed)\r\n",
        "        image_processed, mask_processed = self.random_flip(image_processed, mask_processed)\r\n",
        "        image_processed, mask_processed = self.random_blur(image_processed, mask_processed)\r\n",
        "        image_processed = self.random_add_brightness(image_processed)\r\n",
        "        image_processed = cv2.cvtColor(image_processed, cv2.COLOR_RGB2GRAY)\r\n",
        "        mask_processed = cv2.resize(mask_processed, dsize=(self.output_size, self.output_size))\r\n",
        "        (thresh, mask_processed) = cv2.threshold(mask_processed, 127, 255, cv2.THRESH_BINARY)\r\n",
        "        image_processed = image_processed/255.0\r\n",
        "        mask_processed = mask_processed/255.0\r\n",
        "        return image_processed, mask_processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTjSkSSVmGtn"
      },
      "source": [
        "class DataLoader(Sequence):\r\n",
        "    def __init__(self, meta_data_path, batch_size, phase='train', input_size=224, output_size=224):\r\n",
        "        self.meta_data_path = meta_data_path\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.phase = phase\r\n",
        "        self.input_size = input_size\r\n",
        "        self.output_size = output_size\r\n",
        "        if self.phase == 'train':\r\n",
        "            self.abs_image_path = \"/content/dataset/Original/Training/\"\r\n",
        "            self.abs_mask_path = \"/content/dataset/MASKS/Training/\"\r\n",
        "        else:\r\n",
        "            self.abs_image_path = \"/content/dataset/Original/Testing/\"\r\n",
        "            self.abs_mask_path = \"/content/dataset/MASKS/Testing/\"\r\n",
        "        self.train_path = None\r\n",
        "        self.test_path = None\r\n",
        "        self.indexes = None\r\n",
        "        self.read_meta_data()\r\n",
        "\r\n",
        "    def read_meta_data(self):\r\n",
        "        files = open(self.meta_data_path)\r\n",
        "        files = json.load(files)\r\n",
        "        self.train_path = files['train'][:]\r\n",
        "        self.test_path = files['test'][:]\r\n",
        "        self.indexes = np.arange(len(self.train_path))\r\n",
        "        self.indexes_test = np.arange(len(self.test_path))\r\n",
        "        return self.train_path, self.test_path\r\n",
        "\r\n",
        "    def process_image(self, image_paths):\r\n",
        "        data_transform = DataAugmentation(input_size=self.input_size, output_size=self.output_size)\r\n",
        "        x_train = []\r\n",
        "        y_train = []\r\n",
        "        for path in image_paths:\r\n",
        "            image = cv2.imread(self.abs_image_path + path)\r\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
        "            # original image in jpg format but mask in png format\r\n",
        "            mask = cv2.imread(self.abs_mask_path + path[:len(path) - 3] + \"png\", cv2.IMREAD_GRAYSCALE)\r\n",
        "            image_processed, mask_processed = data_transform.data_process(image, mask)\r\n",
        "            image_processed = np.expand_dims(image_processed, axis=2)\r\n",
        "            mask_processed = np.expand_dims(mask_processed, axis=2)\r\n",
        "            x_train.append(tf.convert_to_tensor(image_processed))\r\n",
        "            y_train.append(tf.convert_to_tensor(mask_processed))\r\n",
        "        return x_train, y_train\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        if self.phase == 'train':\r\n",
        "            index_list = self.indexes\r\n",
        "            data_path = self.train_path\r\n",
        "        else:\r\n",
        "            index_list = self.indexes_test\r\n",
        "            data_path = self.test_path\r\n",
        "        if index == self.__len__()-1:\r\n",
        "            indexes = index_list[index * self.batch_size:]\r\n",
        "        else:\r\n",
        "            indexes = index_list[index*self.batch_size:(index+1)*self.batch_size]\r\n",
        "        image_paths = [data_path[k] for k in indexes]\r\n",
        "        image, mask = self.process_image(image_paths)\r\n",
        "        image = tf.convert_to_tensor(image)\r\n",
        "        mask = tf.convert_to_tensor(mask)\r\n",
        "        return image, mask\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        if self.phase == 'train':\r\n",
        "            num_path = len(self.train_path)\r\n",
        "        else:\r\n",
        "            num_path = len(self.test_path)\r\n",
        "        return int(np.ceil(num_path / self.batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKmzOfIInK-q"
      },
      "source": [
        "META_DATA_PATH = \"/content/dataset/data.json\"\r\n",
        "TRAINING_DATA_PATH = \"/content/dataset/Original/Training/\"\r\n",
        "TRAINING_MASK_PATH = \"/content/dataset/MASKS/Training/\"\r\n",
        "TESTING_DATA_PATH = \"/content/dataset/Original/Testing/\"\r\n",
        "TESTING_MASK_PATH = \"/content/dataset/MASKS/Testing/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-UIwlVnjPy"
      },
      "source": [
        "# Hyper parameters\r\n",
        "BATCH_SIZE = 32\r\n",
        "LR = 0.0015\r\n",
        "EPOCHS = 30\r\n",
        "MOMENTUM = 0.9\r\n",
        "NUM_CLASS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3qhgt9u-o-k"
      },
      "source": [
        "def scheduler(epoch, lr):\r\n",
        "    if epoch != 0 and epoch % 5 == 0:\r\n",
        "        return lr * 0.3\r\n",
        "    else:\r\n",
        "        return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ibVsrlVnmb2"
      },
      "source": [
        "train_generator = DataLoader(META_DATA_PATH, batch_size=BATCH_SIZE, phase='train')\r\n",
        "test_generator = DataLoader(META_DATA_PATH, batch_size=BATCH_SIZE, phase='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-1M-VBdLgv7"
      },
      "source": [
        "model = Unet(input_shape=(224, 224, 1)).build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvRO_tgPyGh"
      },
      "source": [
        "smooth = 1e-15\r\n",
        "def iou(y_true, y_pred):\r\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\r\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\r\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\r\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\r\n",
        "    return (intersection + smooth) / (union + smooth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hewqKLV-LhxW"
      },
      "source": [
        "losses = tf.keras.losses.BinaryCrossentropy()\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\r\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\r\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\r\n",
        "#metric = tf.keras.metrics.MeanIoU(num_classes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBxgxqwKLirp"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=losses, metrics=iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KhUj6an1zIm"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uditn3p4npRk"
      },
      "source": [
        "model.fit_generator(train_generator,\r\n",
        "                    steps_per_epoch=len(train_generator),\r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    callbacks=[callback],\r\n",
        "                    validation_data=test_generator,\r\n",
        "                    validation_steps=len(test_generator))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tlOvuVdQII6"
      },
      "source": [
        "model.save('/content/drive/MyDrive/BAP Colab/HairSegmentation/model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy0peg6V5Iy3"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/BAP Colab/HairSegmentation/model_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}